{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1， 迁移学习是认为别人的Resnet，googlenet这些输出的是特征，是图像的特征。我们自己建立分类模型，对着1000个特征进行处理即可\\n2， finetune是把别人的模型的已经训练好的参数，作为我们的初始化参数，这样，收敛速度快，而且需要的计算力也小。\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1， 迁移学习是认为别人的Resnet，googlenet这些输出的是特征，是图像的特征。我们自己建立分类模型，对着1000个特征进行处理即可\n",
    "2， finetune是把别人的模型的已经训练好的参数，作为我们的初始化参数，这样，收敛速度快，而且需要的计算力也小。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader_image_classification import ImageTransform,make_datapath_list,HymenopteraDataSet\n",
    "\n",
    "size = 224\n",
    "mean = [0.485,0.456,0.406]\n",
    "std = [0.229,0.224,0.225]\n",
    "\n",
    "train_list = make_datapath_list(phase='train')\n",
    "val_list = make_datapath_list(phase='val')\n",
    "\n",
    "train_dataset = HymenopteraDataSet(file_list=train_list,transform=ImageTransform(size,mean,std),phase='train')\n",
    "val_dataset = HymenopteraDataSet(file_list=val_list,transform=ImageTransform(size,mean,std),phase='val')   \n",
    "\n",
    "#  创建DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size,shuffle=False)\n",
    "\n",
    "# 集中到字典变量中\n",
    "dataloader_dict = {'train':train_dataloader,'val':val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建网络模型\n",
    "use_pretrained = True\n",
    "net = models.vgg16(pretrained=use_pretrained)\n",
    "\n",
    "net.classifier[6] = nn.Linear(in_features=4096,out_features=2)\n",
    "\n",
    "net.train()\n",
    "\n",
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存到params_to_update_1： features.0.weight\n",
      "保存到params_to_update_1： features.0.bias\n",
      "保存到params_to_update_1： features.2.weight\n",
      "保存到params_to_update_1： features.2.bias\n",
      "保存到params_to_update_1： features.5.weight\n",
      "保存到params_to_update_1： features.5.bias\n",
      "保存到params_to_update_1： features.7.weight\n",
      "保存到params_to_update_1： features.7.bias\n",
      "保存到params_to_update_1： features.10.weight\n",
      "保存到params_to_update_1： features.10.bias\n",
      "保存到params_to_update_1： features.12.weight\n",
      "保存到params_to_update_1： features.12.bias\n",
      "保存到params_to_update_1： features.14.weight\n",
      "保存到params_to_update_1： features.14.bias\n",
      "保存到params_to_update_1： features.17.weight\n",
      "保存到params_to_update_1： features.17.bias\n",
      "保存到params_to_update_1： features.19.weight\n",
      "保存到params_to_update_1： features.19.bias\n",
      "保存到params_to_update_1： features.21.weight\n",
      "保存到params_to_update_1： features.21.bias\n",
      "保存到params_to_update_1： features.24.weight\n",
      "保存到params_to_update_1： features.24.bias\n",
      "保存到params_to_update_1： features.26.weight\n",
      "保存到params_to_update_1： features.26.bias\n",
      "保存到params_to_update_1： features.28.weight\n",
      "保存到params_to_update_1： features.28.bias\n",
      "保存到params_to_update_2： classifier.0.weight\n",
      "保存到params_to_update_2： classifier.0.bias\n",
      "保存到params_to_update_2： classifier.3.weight\n",
      "保存到params_to_update_2： classifier.3.bias\n",
      "保存到params_to_update_3： classifier.6.weight\n",
      "保存到params_to_update_3： classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# 微调算法与迁移学习 不同， 这里将optimizer设置为全部网络层参数都可以学习\n",
    "\n",
    "# python 列表是可变类型，里面存储的元素会自动更新最新值\n",
    "\n",
    "params_to_update_1 = []\n",
    "params_to_update_2 = []\n",
    "params_to_update_3 = []\n",
    "\n",
    "update_param_names_1 = [\"features\"]\n",
    "update_param_names_2 = [\"classifier.0.weight\",\n",
    "                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
    "update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    \n",
    "    if update_param_names_1[0] in name:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_1.append(param)\n",
    "        print(\"保存到params_to_update_1：\", name)\n",
    "\n",
    "    elif name in update_param_names_2:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_2.append(param)\n",
    "        print(\"保存到params_to_update_2：\", name)\n",
    "\n",
    "    elif name in update_param_names_3:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_3.append(param)\n",
    "        print(\"保存到params_to_update_3：\", name)\n",
    "\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        print(\"不计算梯度，不学习\", name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置各参数的最优化算法\n",
    "optimizer = optim.SGD([\n",
    "    {'params': params_to_update_1, 'lr': 1e-4},\n",
    "    {'params': params_to_update_2, 'lr': 5e-4},\n",
    "    {'params': params_to_update_3, 'lr': 1e-3}\n",
    "], momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net,dataloader_dict,criterion,optimizer,num_epochs):\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    net.to(device)\n",
    "\n",
    "    # 如果网络达到稳定的程度，则开启加速\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1,num_epochs))\n",
    "        print('----'*5)\n",
    "\n",
    "        # 每个epoch中的学习和循环\n",
    "        for phase in ['train','val']:\n",
    "            if phase=='train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "\n",
    "            # 为了对比，未训练与训练的验证能力，epoch=0时候，不训练，直接进行val\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "\n",
    "            # 载入数据\n",
    "            for inputs,labels in tqdm(dataloader_dict[phase]):\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 初始化optimizer\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 计算正向传播\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs,labels)\n",
    "                    _,preds = torch.max(outputs,1)\n",
    "\n",
    "                    # 训练状态 进行反向传播\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 计算迭代结果\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # 显示每个epoch的loss和准确率\n",
    "            epoch_loss = epoch_loss / len(dataloader_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloader_dict[phase].dataset)\n",
    "            \n",
    "            print('{} loss: {:.4f} Acc:{:.4f}'.format(phase, epoch_loss,epoch_acc))\n",
    "\n",
    "        print('============'*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.7703 Acc:0.4444\n",
      "============================================================\n",
      "Epoch 2/2\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:08<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5051 Acc:0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.1829 Acc:0.9608\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 运行\n",
    "num_epochs = 2\n",
    "train_model(net,dataloader_dict,criterion,optimizer,num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "save_path = './model_params/vgg16_fine_tuning.pth'\n",
    "torch.save(net.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 载入模型\n",
    "load_path = './model_params/vgg16_fine_tuning.pth'\n",
    "load_weights = torch.load(load_path)\n",
    "\n",
    "net = models.vgg16(pretrained=use_pretrained)\n",
    "net.classifier[6] = nn.Linear(in_features=4096,out_features=2)\n",
    "net.load_state_dict(load_weights)  # GPU模型\n",
    "\n",
    "'''\n",
    "# 在GPU上保存的权重，使用CPU读取\n",
    "'''\n",
    "net = models.vgg16(pretrained=use_pretrained)\n",
    "net.classifier[6] = nn.Linear(in_features=4096,out_features=2)\n",
    "net.load_state_dict(load_weights)\n",
    "load_weights = torch.load(load_path,map_location={'cuda:0':'cpu'})\n",
    "net.load_state_dict(load_weights) # CPU模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdc6be1e61718cba4ab739a07876a92ebdf3f96fedb5b4437a1b4aa96fa73e01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
